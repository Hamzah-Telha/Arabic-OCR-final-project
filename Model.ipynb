{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir=Path('preprocessed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = list(image_dir.glob(r'**/*.png'))\n",
    "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "image_df1 = pd.concat([filepaths, labels], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Import label encoder\n",
    "# from sklearn import preprocessing\n",
    "  \n",
    "# # label_encoder object knows how to understand word labels.\n",
    "# label_encoder = preprocessing.LabelEncoder()\n",
    "  \n",
    "# # Encode labels in column 'species'.\n",
    "# image_df1['Label']= label_encoder.fit_transform(image_df1['Label'])\n",
    "  \n",
    "# image_df1['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>preprocessed/21_gaf/gaf_mid/20.png</td>\n",
       "      <td>gaf_mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>preprocessed/21_gaf/gaf_mid/22.png</td>\n",
       "      <td>gaf_mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preprocessed/21_gaf/gaf_mid/42.png</td>\n",
       "      <td>gaf_mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>preprocessed/21_gaf/gaf_mid/49.png</td>\n",
       "      <td>gaf_mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>preprocessed/21_gaf/gaf_mid/21.png</td>\n",
       "      <td>gaf_mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>preprocessed/25_non/non_begin/66.png</td>\n",
       "      <td>non_begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>preprocessed/25_non/non_begin/327.png</td>\n",
       "      <td>non_begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>preprocessed/25_non/non_begin/387.png</td>\n",
       "      <td>non_begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>preprocessed/25_non/non_begin/185.png</td>\n",
       "      <td>non_begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>preprocessed/25_non/non_begin/196.png</td>\n",
       "      <td>non_begin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Filepath      Label\n",
       "0       preprocessed/21_gaf/gaf_mid/20.png    gaf_mid\n",
       "1       preprocessed/21_gaf/gaf_mid/22.png    gaf_mid\n",
       "2       preprocessed/21_gaf/gaf_mid/42.png    gaf_mid\n",
       "3       preprocessed/21_gaf/gaf_mid/49.png    gaf_mid\n",
       "4       preprocessed/21_gaf/gaf_mid/21.png    gaf_mid\n",
       "..                                     ...        ...\n",
       "835   preprocessed/25_non/non_begin/66.png  non_begin\n",
       "836  preprocessed/25_non/non_begin/327.png  non_begin\n",
       "837  preprocessed/25_non/non_begin/387.png  non_begin\n",
       "838  preprocessed/25_non/non_begin/185.png  non_begin\n",
       "839  preprocessed/25_non/non_begin/196.png  non_begin\n",
       "\n",
       "[840 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df1.to_csv('image_labels.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(image_df1, train_size=0.7, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 471 validated image filenames belonging to 42 classes.\n",
      "Found 117 validated image filenames belonging to 42 classes.\n",
      "Found 252 validated image filenames belonging to 42 classes.\n"
     ]
    }
   ],
   "source": [
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(10, 22),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=20,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(10, 22),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=20,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(10, 22),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=20,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical, image_dataset_from_directory\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "inputs = tf.keras.Input(shape=(10, 22))\n",
    "# Preprocessing \n",
    "model.add(layers.Resizing(height=128, width=128, interpolation='bilinear'))\n",
    "model.add(layers.Rescaling(scale=1./255))\n",
    "\n",
    "# Data Augmentation\n",
    "#model.add(layers.RandomFlip(mode='horizontal_and_vertical'))\n",
    "#model.add(layers.RandomRotation(factor=.2))\n",
    "\n",
    "# First Convolution\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(1,5), input_shape = (224,224,3)))\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(5,1)))\n",
    "model.add(layers.Activation('leaky_relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(.2))\n",
    "\n",
    "# Second Convolution\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(1,3)))\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3,1)))\n",
    "model.add(layers.Activation('leaky_relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(.2))\n",
    "\n",
    "# Third Convolution\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(1,3)))\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3,1)))\n",
    "model.add(layers.Activation('leaky_relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(.2))\n",
    "\n",
    "# Feed forward\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.Activation('leaky_relu'))\n",
    "model.add(layers.Dropout(.2))\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.Activation('leaky_relu'))\n",
    "model.add(layers.Dropout(.2))\n",
    "model.add(layers.Dense(42))\n",
    "model.add(layers.Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 06:52:44.331601: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - ETA: 0s - loss: 6.0225 - accuracy: 0.0446"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 06:52:53.921268: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 10s 376ms/step - loss: 6.0225 - accuracy: 0.0446 - val_loss: 10.1135 - val_accuracy: 0.0256 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 9s 376ms/step - loss: 5.2583 - accuracy: 0.0340 - val_loss: 16.3112 - val_accuracy: 0.0256 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 9s 374ms/step - loss: 4.4242 - accuracy: 0.0318 - val_loss: 20.5185 - val_accuracy: 0.0342 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 9s 379ms/step - loss: 4.1696 - accuracy: 0.0616 - val_loss: 24.2464 - val_accuracy: 0.0342 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 9s 382ms/step - loss: 3.8482 - accuracy: 0.0701 - val_loss: 20.8221 - val_accuracy: 0.0342 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 9s 377ms/step - loss: 3.3389 - accuracy: 0.0977 - val_loss: 20.9133 - val_accuracy: 0.0342 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "         tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            patience=3\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The channel dimension of the inputs should be defined. The input_shape received is (None, 128, 128, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m load_model\n\u001b[1;32m      3\u001b[0m \u001b[39m# Load the saved model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39;49m\u001b[39mModel.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# Use the model to make predictions on new data\u001b[39;00m\n\u001b[1;32m      7\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(train_images)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/saving/saving_api.py:212\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[1;32m    205\u001b[0m         filepath,\n\u001b[1;32m    206\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[1;32m    207\u001b[0m         \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m,\n\u001b[1;32m    208\u001b[0m         safe_mode\u001b[39m=\u001b[39msafe_mode,\n\u001b[1;32m    209\u001b[0m     )\n\u001b[1;32m    211\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m    213\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39;49mcustom_objects, \u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcompile\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    214\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py:416\u001b[0m, in \u001b[0;36mConv._get_input_channel\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    414\u001b[0m channel_axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_channel_axis()\n\u001b[1;32m    415\u001b[0m \u001b[39mif\u001b[39;00m input_shape\u001b[39m.\u001b[39mdims[channel_axis]\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    417\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe channel dimension of the inputs should be defined. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe input_shape received is \u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhere axis \u001b[39m\u001b[39m{\u001b[39;00mchannel_axis\u001b[39m}\u001b[39;00m\u001b[39m (0-based) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    420\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mis the channel dimension, which found to be `None`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    421\u001b[0m     )\n\u001b[1;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mint\u001b[39m(input_shape[channel_axis])\n",
      "\u001b[0;31mValueError\u001b[0m: The channel dimension of the inputs should be defined. The input_shape received is (None, 128, 128, None), where axis -1 (0-based) is the channel dimension, which found to be `None`."
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('Model.h5')\n",
    "\n",
    "# Use the model to make predictions on new data\n",
    "predictions = model.predict(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
