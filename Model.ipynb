{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir=Path('preprocessed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = list(image_dir.glob(r'**/*.png'))\n",
    "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "image_df1 = pd.concat([filepaths, labels], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Import label encoder\n",
    "# from sklearn import preprocessing\n",
    "  \n",
    "# # label_encoder object knows how to understand word labels.\n",
    "# label_encoder = preprocessing.LabelEncoder()\n",
    "  \n",
    "# # Encode labels in column 'species'.\n",
    "# image_df1['Label']= label_encoder.fit_transform(image_df1['Label'])\n",
    "  \n",
    "# image_df1['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>preprocessed/alif/477.png</td>\n",
       "      <td>alif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>preprocessed/alif/2976.png</td>\n",
       "      <td>alif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preprocessed/alif/4278.png</td>\n",
       "      <td>alif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>preprocessed/alif/4216.png</td>\n",
       "      <td>alif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>preprocessed/alif/791.png</td>\n",
       "      <td>alif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12579</th>\n",
       "      <td>preprocessed/ta/523.png</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12580</th>\n",
       "      <td>preprocessed/ta/3207.png</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12581</th>\n",
       "      <td>preprocessed/ta/2989.png</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12582</th>\n",
       "      <td>preprocessed/ta/1812.png</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12583</th>\n",
       "      <td>preprocessed/ta/4065.png</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12584 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Filepath Label\n",
       "0       preprocessed/alif/477.png  alif\n",
       "1      preprocessed/alif/2976.png  alif\n",
       "2      preprocessed/alif/4278.png  alif\n",
       "3      preprocessed/alif/4216.png  alif\n",
       "4       preprocessed/alif/791.png  alif\n",
       "...                           ...   ...\n",
       "12579     preprocessed/ta/523.png    ta\n",
       "12580    preprocessed/ta/3207.png    ta\n",
       "12581    preprocessed/ta/2989.png    ta\n",
       "12582    preprocessed/ta/1812.png    ta\n",
       "12583    preprocessed/ta/4065.png    ta\n",
       "\n",
       "[12584 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df1.to_csv('image_labels.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(image_df1, train_size=0.7, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7047 validated image filenames belonging to 3 classes.\n",
      "Found 1761 validated image filenames belonging to 3 classes.\n",
      "Found 3776 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(7, 22),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(7, 22),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(7, 22),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical, image_dataset_from_directory\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "inputs = tf.keras.Input(shape=(7, 22))\n",
    "# Preprocessing \n",
    "model.add(layers.Resizing(height=128, width=128, interpolation='bilinear'))\n",
    "model.add(layers.Rescaling(scale=1./255))\n",
    "\n",
    "# Data Augmentation\n",
    "#model.add(layers.RandomFlip(mode='horizontal_and_vertical'))\n",
    "#model.add(layers.RandomRotation(factor=.2))\n",
    "\n",
    "# First Convolution\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(1,5), input_shape = (224,224,3)))\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(5,1)))\n",
    "model.add(layers.Activation('leaky_relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(.2))\n",
    "\n",
    "# Second Convolution\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(1,3)))\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3,1)))\n",
    "model.add(layers.Activation('leaky_relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(.2))\n",
    "\n",
    "# Third Convolution\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(1,3)))\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3,1)))\n",
    "model.add(layers.Activation('leaky_relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(.2))\n",
    "\n",
    "# Feed forward\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.Activation('leaky_relu'))\n",
    "model.add(layers.Dropout(.2))\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.Activation('leaky_relu'))\n",
    "model.add(layers.Dropout(.2))\n",
    "model.add(layers.Dense(3))\n",
    "model.add(layers.Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 08:49:02.596261: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221/221 [==============================] - ETA: 0s - loss: 1.6579 - accuracy: 0.6474"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 08:51:26.905575: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221/221 [==============================] - 158s 690ms/step - loss: 1.6579 - accuracy: 0.6474 - val_loss: 22.7006 - val_accuracy: 0.3294 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "221/221 [==============================] - 123s 556ms/step - loss: 0.7931 - accuracy: 0.6824 - val_loss: 23.3610 - val_accuracy: 0.3294 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "221/221 [==============================] - 121s 546ms/step - loss: 0.6432 - accuracy: 0.6956 - val_loss: 11.9288 - val_accuracy: 0.5003 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "221/221 [==============================] - 124s 560ms/step - loss: 0.5758 - accuracy: 0.7190 - val_loss: 0.9207 - val_accuracy: 0.7087 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "221/221 [==============================] - 123s 557ms/step - loss: 0.5295 - accuracy: 0.7331 - val_loss: 0.9706 - val_accuracy: 0.7081 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    epochs=5,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "         tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            patience=3\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
