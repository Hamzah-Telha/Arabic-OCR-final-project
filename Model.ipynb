{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "from sklearn.metrics import confusion_matrix, classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir=Path('preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = list(image_dir.glob(r'**/*.png'))\n",
    "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "image_df1 = pd.concat([filepaths, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Import label encoder\n",
    "# from sklearn import preprocessing\n",
    "  \n",
    "# # label_encoder object knows how to understand word labels.\n",
    "# label_encoder = preprocessing.LabelEncoder()\n",
    "  \n",
    "# # Encode labels in column 'species'.\n",
    "# image_df1['Label']= label_encoder.fit_transform(image_df1['Label'])\n",
    "  \n",
    "# image_df1['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df1.to_csv('image_labels.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(image_df1, train_size=0.75, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(128, 128),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    batch_size=20,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(128, 128),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    batch_size=20,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(128, 128),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    batch_size=20,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch = next(train_images)\n",
    "# for i in range(batch[0].shape[0]):\n",
    "plt.imshow(batch[0][9], cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "# Modify the input shape to have 1 channel\n",
    "inputs = tf.keras.Input(shape=(128, 128, 1))\n",
    "\n",
    "# Preprocessing\n",
    "model.add(layers.Resizing(height=128, width=128, interpolation='bilinear'))\n",
    "model.add(layers.Rescaling(scale=1./255))\n",
    "\n",
    "# Data Augmentation\n",
    "# model.add(layers.RandomFlip(mode='horizontal_and_vertical'))\n",
    "# model.add(layers.RandomRotation(factor=.2))\n",
    "\n",
    "# First Convolution\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(5, 5),\n",
    "          padding='same', input_shape=(128, 128, 1)))\n",
    "model.add(layers.Activation(tf.keras.activations.relu))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(.2))\n",
    "\n",
    "# Second Convolution\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(layers.Activation(tf.keras.activations.relu))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(.2))\n",
    "\n",
    "# Third Convolution\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(layers.Activation(tf.keras.activations.relu))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(.2))\n",
    "\n",
    "# Feed forward\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(\n",
    "    0.01), bias_regularizer=regularizers.l2(0.01)))\n",
    "model.add(layers.Activation(tf.keras.activations.relu))\n",
    "model.add(layers.Dropout(.2))\n",
    "model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(\n",
    "    0.01), bias_regularizer=regularizers.l2(0.01)))\n",
    "model.add(layers.Activation(tf.keras.activations.relu))\n",
    "model.add(layers.Dropout(.2))\n",
    "model.add(layers.Dense(42))\n",
    "model.add(layers.Activation(tf.keras.activations.softmax))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    epochs=5,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "         tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            patience=3\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to make predictions on new data\n",
    "predictions = model.predict(test_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
